---
title: "Customer Retention Project"
output: html_notebook
---

### Install Required Libraries
```{r}
# Uncomment respective line for which package is missing.
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("reshape2")
#install.packages("corrplot")
```

### Load Required Libraries
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(corrplot)
```

### Datasets

### Load Datasets
```{r}
implementation_data <- "Implementation_Data.rda"
load(implementation_data)

model_building_data <- "Model_Building_Data.rda"
load(model_building_data)
```

### Implementation Dataset Quick View
```{r}
head(Implementation_Data)
str(Implementation_Data)
```

### Model Building Dataset Quick View
```{r}
head(Model_Building_Data)
str(Model_Building_Data)
```

# 1. Data Preparation & Exploratory Data Analysis
**Data preparation** is cleaning and organizing data, while **Exploratory Data Analysis (EDA)** helps explore patterns and trends using summaries and visuals.

## 1.1 Data Preparation
### Datatypes
**Status** is loaded as *chr* and having `r length(unique(Model_Building_Data$Status))` values only so it can be converted into *factor*
```{r}
Model_Building_Data$Status <- as.factor(Model_Building_Data$Status)
```

**SeniorCitizen** is loaded as an *integer* it can be converted into a *factor* for better machine learning analysis.
```{r}
Model_Building_Data$SeniorCitizen <- as.factor(Model_Building_Data$SeniorCitizen)
```

### Missing Values
There are multiple ways to handle missing values:

* Removing -> If missing values are very few <5% of data.
* Mean -> If normally distributed.
* Median -> If data is skewed.
* Regression -> Many missing values.

Let's check missing values for all the columns:
```{r}
sapply(Model_Building_Data, function(x) sum(is.na(x)))
```
We have 11 missing values for **TotalCharges** column which is very small less (<5% of data) so we can remove missing records.
Let's check the histogram and analyze the distribution of the data.
```{r}
hist(Model_Building_Data$TotalCharges, 
     breaks = 30, 
     main = "Distribution of Total Charges", 
     xlab = "Total Charges ($)", 
     ylab = "Customers", 
     col = "skyblue")

```
*TotalCharges* is right skewed, so we can use median in order to update missing records.
```{r}
Model_Building_Data$TotalCharges[is.na(Model_Building_Data$TotalCharges)] <- median(Model_Building_Data$TotalCharges, na.rm = TRUE)
```

Now cross check the whether missing values are handled or not
```{r}
sapply(Model_Building_Data, function(x) sum(is.na(x)))
```

## 1.2 Exploratory Data Analysis
TODO: Repeat for all Factor columns

```{r}
ggplot(Model_Building_Data, aes(x = PaymentMethod)) +
  geom_bar(fill = "skyblue", color="black", alpha = 0.6) +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.6, size = 3) +
  theme_minimal(base_size = 12) +
  labs(title = "Bar Plot of PaymentMethod", x = "PaymentMethod", y = "Customers")
```
TODO: Explain bar plot and your findings.

TODO: You can also use pie chart instead of barplot.
```{r}
status_counts <- table(Model_Building_Data$Status)
status_df <- as.data.frame(status_counts)
status_df$percentage <- round(100 * status_df$Freq / sum(status_df$Freq), 1)
ggplot(status_df, aes(x = "", y = Freq, fill = Var1)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Distribution of Status") +
  theme_void() +
  theme(legend.title = element_blank()) +
  geom_text(aes(label = paste(percentage, "%")), position = position_stack(vjust = 0.5))
```
TODO: Mention that the dataset is imbalanced, we can use undersampling or oversampling or synthetic records generation if model is not performing well with this imbalanced dataset.


TODO: Repeat for all numeric columns and adjust bins as required
```{r}
ggplot(Model_Building_Data, aes(x = Tenure)) +
  geom_histogram(binwidth = 10, boundary = 0, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Tenure", x = "Tenure (Bin=10)", y = "Customers") +
  theme_minimal()
```

TODO: Explain histogram plot and your findings.

### Correlation
```{r}
data_numeric <- Model_Building_Data %>%
  mutate(across(where(is.factor), as.numeric))
cor_matrix <- cor(data_numeric, use = "complete.obs")

# Displaying correlation after rounding
#print(round(cor_matrix, 2))
corrplot(cor_matrix, method = "color",
         tl.col = "black",
         tl.cex = 0.8,
         addCoef.col = "black",
         number.cex = 0.4,
         number.font = 2,
         number.digits = 2)
```

TODO: Explain all important correlations between 1. independent to independent variables, 2. independent to dependent variable. i.e, all possible correlations (focus on highly +ve/-ve correlations)

### Training and Testing Dataset Preparation
We are dividing the entire dataset into 80% for training and 20% for testing.




